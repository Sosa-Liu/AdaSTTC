{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TaxiBJ: InFlow/OutFlow, Meteorology and Holiday ai Beijing\n",
    "==========================================================\n",
    "\n",
    "**Proposed by the following paper:**\n",
    "\n",
    "`Junbo Zhang, Yu Zheng, Dekang Qi. Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction. In AAAI 2017. `\n",
    "\n",
    "**TaxiBJ** consists of the following **6** files:\n",
    "\n",
    "* BJ16_M32x32_T30_InOut.h5\n",
    "* BJ15_M32x32_T30_InOut.h5\n",
    "* BJ14_M32x32_T30_InOut.h5\n",
    "* BJ13_M32x32_T30_InOut.h5\n",
    "* BJ_Meteorology.h5\n",
    "* BJ_Holiday.txt\n",
    "\n",
    "where the first four files are *crowd flows* in Beijing from the year 2013 to 2016, `BJ_Meteorology.h5` is the Meteorological data, `BJ_Holiday.txt` includes the holidays (and adjacent weekends) of Beijing. \n",
    "\n",
    "The taxicab GPS data and meteorology data in Beijing from four time intervals: \n",
    "\n",
    "- 1st Jul. 2013 - 30th Otc. 2013, \n",
    "- 1st Mar. 2014 - 30th Jun. 2014, \n",
    "- 1st Mar. 2015 - 30th Jun. 2015, \n",
    "- 1st Nov. 2015 - 10th Apr. 2016. \n",
    "\n",
    "The Beijing city map is divided into **32 Ã— 32 grids** and the time interval of the flow data is **30 minutes**. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `1. View dataset`\n",
    "### 1.1 Flows of Crowds\n",
    "\n",
    "File names: `BJ[YEAR]_M32x32_T30_InOut.h5`, where\n",
    "\n",
    "* YEAR: one of {13, 14, 15, 16}\n",
    "* M32x32: the Beijing city is divided into a 32 x 32 grid map\n",
    "* T30: timeslot (a.k.a. time interval) is equal to 30 minites, meaning there are 48 timeslots in a day\n",
    "* InOut: Inflow/Outflow are defined in the following paper \n",
    "\n",
    "Each `*.h5` file has two following subsets:\n",
    "\n",
    "* `date`: a list of timeslots, which is associated the **data**. \n",
    "* `data`: a 4D tensor of shape (number_of_timeslots, 2, 32, 32), of which `data[i]` is a 3D tensor of shape (2, 32, 32) at the timeslot `date[i]`, `data[i][0]` is a `32x32` inflow matrix and `data[i][1]` is a `32x32` outflow matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BJ2013:\n",
      "data (4888, 2, 32, 32)\n",
      "date (4888,)\n",
      "BJ2014:\n",
      "data (4780, 2, 32, 32)\n",
      "date (4780,)\n",
      "BJ2015:\n",
      "data (5596, 2, 32, 32)\n",
      "date (5596,)\n",
      "BJ2016:\n",
      "data (7220, 2, 32, 32)\n",
      "date (7220,)\n"
     ]
    }
   ],
   "source": [
    "# view the data\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "DATAPATH = 'f:/sosa_data/TaxiBJ/'\n",
    "\n",
    "for i in range(13,17):\n",
    "    f = h5py.File(os.path.join(DATAPATH, 'BJ{}_M32x32_T30_InOut.h5'.format(str(i))), 'r')\n",
    "    print(f'BJ20{str(i)}:')\n",
    "    for k in f.keys():\n",
    "        print(k, f[k].shape)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import h5py\n",
    "\n",
    "def inspect_flow(file_flow, interval=30, T=48):\n",
    "    '''print info of file)flow'''\n",
    "    with h5py.File(file_flow) as f:\n",
    "        # get the first and the last timeslot\n",
    "        start = f['date'][0]\n",
    "        end = f['date'][-1]\n",
    "\n",
    "        # convert timeslot to struct_time and format string 'YYYY-MM-DD'\n",
    "        year, month, day = map(int, [start[:4], start[4:6], start[6:8]])\n",
    "        date_start = time.strptime('%04i-%02i-%02i' % (year, month, day), '%Y-%m-%d')\n",
    "        date_start_str = time.strftime('%Y-%m-%d', date_start)\n",
    "\n",
    "        year, month, day = map(int, [end[:4], end[4:6], end[6:8]])\n",
    "        date_end = time.strptime('%04i-%02i-%02i' % (year, month, day), '%Y-%m-%d')\n",
    "        date_end_str = time.strftime('%Y-%m-%d', date_end)\n",
    "\n",
    "        # compute the total number of timeslots and days\n",
    "        num_timeslots = (time.mktime(date_end) - time.mktime(date_start)) / (interval * 60) + T\n",
    "        num_days = int(num_timeslots / T)\n",
    "\n",
    "        max_flow = f['data'][:].max()\n",
    "        min_flow = f['data'][:].min()\n",
    "\n",
    "        info = '*-' * 10 + 'flow info' + '*-' * 10 + '\\n' + \\\n",
    "            'data shape: %s\\n' % str(f['data'].shape) + \\\n",
    "            '#days: %i, from %s to %s\\n' % (num_days, date_start_str, date_end_str) + \\\n",
    "            '#timeslots(due): %i, #timeslots(available): %i\\n' % (int(num_timeslots), f['date'].shape[0]) + \\\n",
    "            'missing ratio of timeslots: %.1f%%\\n' % ((1. - float(f['date'].shape[0]) / num_timeslots) * 100) + \\\n",
    "            f'max_flow: {max_flow:.3f}, min_flow: {min_flow:.3f}\\n' \n",
    "\n",
    "        print(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*-*-*-*-*-*-*-*-*-*-flow info*-*-*-*-*-*-*-*-*-*-\n",
      "data shape: (4888, 2, 32, 32)\n",
      "#days: 121, from 2013-07-01 to 2013-10-29\n",
      "#timeslots(due): 5808, #timeslots(available): 4888\n",
      "missing ratio of timeslots: 15.8%\n",
      "max_flow: 1230.000, min_flow: 0.000\n",
      "\n",
      "*-*-*-*-*-*-*-*-*-*-flow info*-*-*-*-*-*-*-*-*-*-\n",
      "data shape: (4780, 2, 32, 32)\n",
      "#days: 119, from 2014-03-01 to 2014-06-27\n",
      "#timeslots(due): 5712, #timeslots(available): 4780\n",
      "missing ratio of timeslots: 16.3%\n",
      "max_flow: 1292.000, min_flow: 0.000\n",
      "\n",
      "*-*-*-*-*-*-*-*-*-*-flow info*-*-*-*-*-*-*-*-*-*-\n",
      "data shape: (5596, 2, 32, 32)\n",
      "#days: 122, from 2015-03-01 to 2015-06-30\n",
      "#timeslots(due): 5856, #timeslots(available): 5596\n",
      "missing ratio of timeslots: 4.4%\n",
      "max_flow: 1274.000, min_flow: 0.000\n",
      "\n",
      "*-*-*-*-*-*-*-*-*-*-flow info*-*-*-*-*-*-*-*-*-*-\n",
      "data shape: (7220, 2, 32, 32)\n",
      "#days: 162, from 2015-11-01 to 2016-04-10\n",
      "#timeslots(due): 7776, #timeslots(available): 7220\n",
      "missing ratio of timeslots: 7.2%\n",
      "max_flow: 1250.000, min_flow: 0.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inspect_flow('f:/sosa_data/TaxiBJ/BJ13_M32x32_T30_InOut.h5')\n",
    "inspect_flow('f:/sosa_data/TaxiBJ/BJ14_M32x32_T30_InOut.h5')\n",
    "inspect_flow('f:/sosa_data/TaxiBJ/BJ15_M32x32_T30_InOut.h5')\n",
    "inspect_flow('f:/sosa_data/TaxiBJ/BJ16_M32x32_T30_InOut.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Meteorology\n",
    "\n",
    "File name: `BJ_Meteorology.h5`, which has four following subsets:\n",
    "\n",
    "* `Temperature`: a list of continuous value, of which the $i^{th}$ value is `temperature` at the timeslot `date[i]`.\n",
    "* `Weather`: a 2D matrix, each of which is a one-hot vector (`dim=17`). \n",
    "* `WindSpeed`: a list of continuous value, of which the $i^{th}$ value is `wind speed` at the timeslot `date[i]`. \n",
    "* `date`: a list of timeslots, which is associated the following kinds of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def inspect_time(timeslots, interval=30, T=48):\n",
    "    start = timeslots[0]\n",
    "    end = timeslots[-1]\n",
    "    year, month, day = map(int, [start[:4], start[4:6], start[6:8]])\n",
    "    start_date = time.strptime(f'{year:04}-{month:02}-{day:02}', '%Y-%m-%d')\n",
    "    start_date_str = time.strftime('%Y-%m-%d', start_date)\n",
    "    year, month, day = map(int, [end[:4], end[4:6], end[6:8]])\n",
    "    end_date = time.strptime(f'{year:04}-{month:02}-{day:02}', '%Y-%m-%d')\n",
    "    end_date_str = time.strftime('%Y-%m-%d', end_date)\n",
    "\n",
    "    num_timelots = int((time.mktime(end_date) - time.mktime(start_date)) / (interval * 60) + T)\n",
    "    num_days = int(num_timelots / T)\n",
    "\n",
    "    info = f'start date: {start_date_str}, end date: {end_date_str}\\n' + \\\n",
    "        f'#days(due): {num_days}\\n' + \\\n",
    "        f'#slots(due): {num_timelots}, #slots(available): {timeslots.shape[0]}\\n'\n",
    "    \n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature (59006,)\n",
      "Weather (59006, 17)\n",
      "WindSpeed (59006,)\n",
      "date (59006,)\n",
      "start date: 2013-02-01, end date: 2016-06-13\n",
      "#days(due): 1229\n",
      "#slots(due): 58992, #slots(available): 59006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "DATAPATH = 'f:/sosa_data/TaxiBJ/'\n",
    "\n",
    "f_meteorology  = h5py.File(os.path.join(DATAPATH, 'BJ_Meteorology.h5'), 'r')\n",
    "for k in f_meteorology:\n",
    "    print(k, f_meteorology[k].shape)\n",
    "inspect_time(f_meteorology['date'])\n",
    "f_meteorology.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Holiday\n",
    "\n",
    "File name: `BJ_Holiday.txt`, which includes a list of the holidays (and adjacent weekends) of Beijing. \n",
    "\n",
    "Each line a holiday with the data format [yyyy][mm][dd]. For example, `20150601` is `June 1st, 2015`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 20130101\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "f_holiday = open(os.path.join(DATAPATH, 'BJ_Holiday.txt'), 'r')\n",
    "holidays = f_holiday.read().split()\n",
    "print(len(holidays), holidays[0])\n",
    "f_holiday.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ` 2. Load data`\n",
    "\n",
    "- `data_flow`: ndarray, (22484, 2, 32, 32)\n",
    "- `timeslot_flow`: ndarray, (22484,)\n",
    "- `meteorology_data`: ndarray, (22484, 19)\n",
    "- `is_holiday`: ndarray, (22484,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "DATAPATH = 'f:/sosa_data/TaxiBJ/'\n",
    "\n",
    "def load_flow(file_path):\n",
    "    '''load inflow and outflow gride data from year 2013 to 2016\n",
    "\n",
    "    Input:\n",
    "    - file_path: Path of the flow data file, a string like '*/TaxiBJ/'\n",
    "\n",
    "    Output:\n",
    "    - data_flow: ndarray of all flow data with shape (22484, 2, 32, 32)\n",
    "    - timeslot_flow: ndarray of all timeslots with shape (22484,)\n",
    "    '''\n",
    "    data_flow = []\n",
    "    timeslot_flow = []\n",
    "    for year in range(13, 17):\n",
    "        file_name = os.path.join(file_path, f'BJ{str(year)}_M32x32_T30_InOut.h5')\n",
    "        f_flow = h5py.File(file_name, 'r')\n",
    "        data = f_flow['data'][()]\n",
    "        timeslot = f_flow['date'][()]\n",
    "        data_flow.append(data)\n",
    "        timeslot_flow.append(timeslot)\n",
    "        f_flow.close()\n",
    "    data_flow = np.vstack(data_flow)\n",
    "    timeslot_flow = np.concatenate(timeslot_flow,axis=0)\n",
    "    return data_flow, timeslot_flow\n",
    "\n",
    "\n",
    "# data_flow, timeslot_flow = load_flow(DATAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_meteorology(timeslots, file_path):\n",
    "    '''load file 'BJ_Meteorology.h5'\n",
    "\n",
    "    Input:\n",
    "    - timeslots: ndarray of timeslots with shape (#timeslots,) , (22484,) if load all data\n",
    "    - file_path: Path of the meteorology data file, a string like '*/TaxiBJ/'\n",
    "\n",
    "    Output:\n",
    "    - meteorology_data:  ndarray with shape (#timeslots, 19), (22484, 19) if load all data\n",
    "    '''\n",
    "    f_meteorology = h5py.File(os.path.join(file_path, 'BJ_Meteorology.h5'), 'r')\n",
    "    Timeslot = f_meteorology['date'][()]\n",
    "    WindSpeed = f_meteorology['WindSpeed'][()]\n",
    "    Weather = f_meteorology['Weather'][()]\n",
    "    Temperature = f_meteorology['Temperature'][()]\n",
    "    f_meteorology.close()\n",
    "\n",
    "    M = dict()  # map timeslot to index\n",
    "    for i, slot in enumerate(Timeslot):\n",
    "        M[slot] = i\n",
    "\n",
    "    WS = []  # WindSpeed\n",
    "    WR = []  # Weather\n",
    "    TE = []  # Temperature\n",
    "    for slot in timeslots:\n",
    "        predicted_id = M[slot]\n",
    "        current_id = predicted_id - 1\n",
    "        WS.append(WindSpeed[current_id])\n",
    "        WR.append(Weather[current_id])\n",
    "        TE.append(Temperature[current_id])\n",
    "\n",
    "    WS = np.asarray(WS) # (?, 1)\n",
    "    WR = np.asarray(WR) # (?, 17)\n",
    "    TE = np.asarray(TE) # (?, 1)\n",
    "\n",
    "    # 0-1 scale\n",
    "    # WS = 1. * (WS - WS.min()) / (WS.max() - WS.min())\n",
    "    # TE = 1. * (TE - TE.min()) / (TE.max() - TE.min())\n",
    "\n",
    "    meteorology_data = np.hstack([WR, WS[:, None], TE[:, None]])    # concatenate all these attributes\n",
    "\n",
    "    return meteorology_data\n",
    "\n",
    "# meteorology_data = load_meteorology(timeslot_flow, DATAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_holiday(timeslots, file_path):\n",
    "    '''load file 'BJ_Holiday.txt' \n",
    "    \n",
    "    Input:\n",
    "    - timeslots: ndarray of timeslots with shape (22484,) if load all data\n",
    "    - file_path: Path of the holiday data file, a string like '*/TaxiBJ/'\n",
    "\n",
    "    Output:\n",
    "    - is_holiday: ndarray of {0, 1} with shape (#timeslots, 1), 1 indicating whether current timeslot is holiday\n",
    "    '''\n",
    "    f_holiday = open(os.path.join(file_path, 'BJ_Holiday.txt'), 'r')\n",
    "    holidays = f_holiday.read().split()\n",
    "    holidays = set([h.strip() for h in holidays])   # remove the leading and trailing whitespace of the string\n",
    "    is_holiday = np.zeros(len(timeslots))\n",
    "    for i, slot in enumerate(timeslots):\n",
    "        s = bytes.decode(slot[:8])  # Decode the bytes to string\n",
    "        if s in holidays:\n",
    "            is_holiday[i] = 1\n",
    "    return is_holiday[:, None]\n",
    "\n",
    "\n",
    "# is_holiday = load_holiday(timeslot_flow, DATAPATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `3. Preprocessing`\n",
    "\n",
    "### 3.1 missing data process\n",
    "\n",
    "Remove the data of days which do not have 48 timestamps, after removed:\n",
    "\n",
    "data_list:\n",
    "- `data_flow`: ndarray, (21360, 2, 32, 32)\n",
    "- `meteorology_data`: ndarray, (21360, 19)\n",
    "- `is_holiday`: ndarray, (21360, 1)\n",
    "  \n",
    "timestamps:\n",
    "- `timestamps`: ndarray, (21360,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_incomplete_days(data, timestamps, T=48):\n",
    "    '''remove a certain day which does not have 48 timestamps\n",
    "    '''\n",
    "    days = []  # available days: some day only contain some seqs\n",
    "    days_incomplete = []\n",
    "    i = 0\n",
    "    while i < len(timestamps):\n",
    "        if int(timestamps[i][8:]) != 1:\n",
    "            i += 1\n",
    "        elif i+T-1 < len(timestamps) and int(timestamps[i+T-1][8:]) == T:\n",
    "            days.append(timestamps[i][:8])\n",
    "            i += T\n",
    "        else:\n",
    "            days_incomplete.append(timestamps[i][:8])\n",
    "            i += 1\n",
    "    days = set(days)\n",
    "    idx = []\n",
    "    for i, t in enumerate(timestamps):\n",
    "        if t[:8] in days:\n",
    "            idx.append(i)\n",
    "\n",
    "    data = data[idx]\n",
    "    timestamps = [timestamps[i] for i in idx]\n",
    "    timestamps = np.asarray(timestamps)\n",
    "\n",
    "    return data, timestamps, days_incomplete\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 get time position feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "sys.path.append(\"E:\\\\AdaSTTP\")\n",
    "\n",
    "from fuzzy_utils import triangular, asymmetric_gaussian, get_triangular_params, get_guassian_params\n",
    "\n",
    "def time_of_day(timestamps, fuzzy=None, time_position_list=[13, 18, 29, 34, 38, 45], T=48):\n",
    "    '''the time position in one day\n",
    "\n",
    "    Input:\n",
    "    - timestampes: A list or ndarray of timeslots with the format 'YYYYMMDDNN', 'NN' indicates the NN^th timeslot in the day 'YYYYMMDD'\n",
    "    - fuzzy: None, 'triangular' or 'guassian', default None. \n",
    "    - time_position_list: None or a list of end time position of each period.\n",
    "\n",
    "    Output:\n",
    "    - time_position: A list of float number indicating which time position period the current slot belongs to.\n",
    "    '''\n",
    "\n",
    "    time_of_day = [int(t[8:10]) for t in timestamps]    # integer [1, T]\n",
    "    # number of positions in one day\n",
    "    num_positions = len(time_position_list)\n",
    "    time_position = []\n",
    "    if fuzzy == None:\n",
    "        for i in time_of_day:\n",
    "            p = [0. for _ in range(num_positions)]\n",
    "            for j in range(num_positions):\n",
    "                if time_position_list[j] >= i:\n",
    "                    p[j] = 1.\n",
    "                    break\n",
    "                elif time_position_list[-1] < i:\n",
    "                    p[0] = 1.\n",
    "            \n",
    "            time_position.append(p)\n",
    "\n",
    "    elif fuzzy == 'triangular':\n",
    "        a_list, b_list, c_list = get_triangular_params(time_position_list)\n",
    "        \n",
    "    elif fuzzy == 'guassian':\n",
    "        a_list, b_list, c_list = get_guassian_params(time_position_list)\n",
    "\n",
    "    for i in time_of_day:\n",
    "        p = [0. for _ in range(num_positions)]\n",
    "        for j in range(num_positions):\n",
    "            a, b, c = a_list[j], b_list[j], c_list[j]\n",
    "            p[j] = triangular(i, a, b, c) if fuzzy == 'triangular' else asymmetric_gaussian(i, a, b, c)\n",
    "    time_position.append(p)\n",
    "\n",
    "    return np.asarray(time_position)\n",
    "\n",
    "\n",
    "def day_of_week(timestamps):\n",
    "    '''day of week, is weekday or not\n",
    "\n",
    "    Input:\n",
    "    - timestampes: A list or ndarray of timeslots with the format 'YYYYMMDDNN', 'NN' indicates the NN^th timeslot in the day 'YYYYMMDD'\n",
    "\n",
    "    Output:\n",
    "    - week_position[:7]: one-hot encoding indicating the day of week\n",
    "    - week_position[7]: 0--weekend, 1--weekday\n",
    "    '''\n",
    "    day_of_week = [time.strptime(str(\n",
    "        t[:8], encoding='utf-8'), '%Y%m%d').tm_wday for t in timestamps]  # tm_wday(): day of week, range [0, 6], Monday is 0\n",
    "    week_position = []\n",
    "    for i in day_of_week:\n",
    "        v = [0 for _ in range(7)]\n",
    "        v[i] = 1\n",
    "        if i >= 5:\n",
    "            v.append(0)  # weekend\n",
    "        else:\n",
    "            v.append(1)  # weekday\n",
    "        week_position.append(v)\n",
    "\n",
    "    return np.asarray(week_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_time_position(timestamps):\n",
    "    '''time of day, day of week, and is weekday or not\n",
    "\n",
    "    Input:\n",
    "    - timestampes: A list or ndarray of timeslots with the format 'YYYYMMDDNN', 'NN' indicates the NN^th timeslot in the day 'YYYYMMDD'\n",
    "\n",
    "    Output:\n",
    "    - time_meta[:7]: one-hot encoding indicating the day of week\n",
    "    - time_meta[7]: 0--weekend, 1--weekday\n",
    "    - time_meta[8:]: membership degree of each time period \n",
    "    '''\n",
    "    week_position = day_of_week(timestamps)\n",
    "    time_position = time_of_day(timestamps)\n",
    "    time_meta = week_position.concatenate(time_position, 0)\n",
    "    \n",
    "    return time_meta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 merge feature\n",
    "\n",
    "- data: (#timestamps, 2, 32, 32)\n",
    "- timestamp: (#timestamps,)\n",
    "- extra_feature: (#timestamps, 28 + #time_periods):\n",
    "  - [:, :17] weather\n",
    "  - [:, 17] wind speed\n",
    "  - [:, 18] temperature\n",
    "  - [:, 19] is_holiday\n",
    "  - [:, 20:27] day of week\n",
    "  - [:, 27] is_workday\n",
    "  - [:, 28:] time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge_feature(out_dir, use_meteorology=True, use_time_meta=True, use_holiday=True):\n",
    "    \"\"\"\n",
    "    load flow data from 2013 to 2016, as well as corresponding extra features\n",
    "    \"\"\"\n",
    "    \n",
    "    data_flow, timeslot_flow = load_flow(DATAPATH)  \n",
    "    # remove data of days with missing values\n",
    "    data_flow_rm, timeslot_flow_rm = remove_incomplete_days(data_flow, timeslot_flow)\n",
    "    data_flow_rm[data_flow_rm<0] = 0.\n",
    "\n",
    "    extra_feature = []\n",
    "    if use_meteorology:\n",
    "        meteorology_feature = load_meteorology(timeslot_flow_rm, DATAPATH)\n",
    "        extra_feature.append(meteorology_feature)\n",
    "        # print('meteorol feature: ', meteorology_feature.shape) -- meteorol feature:  (21360, 19)\n",
    "    if use_holiday:\n",
    "        holiday_feature = load_holiday(timeslot_flow_rm, DATAPATH)\n",
    "        extra_feature.append(holiday_feature)\n",
    "        # print('holiday feature:', holiday_feature.shape) -- holiday feature: (21360, 1)\n",
    "    if use_time_meta:\n",
    "        time_meta_feature = load_time_position(timeslot_flow_rm)\n",
    "        extra_feature.append(time_meta_feature)\n",
    "        # print('time feature:', time_meta_feature.shape)  -- time feature: (21360, 8)\n",
    "\n",
    "\n",
    "    extra_feature = np.hstack(extra_feature) if len(extra_feature) > 0 else np.asarray(extra_feature)\n",
    "    # print('mete feature: ', meta_feature.shape) -- mete feature:  (21360, 28)\n",
    "\n",
    "    np.savez(out_dir, data=data_flow_rm, timestamp=timeslot_flow_rm, extra_feature=extra_feature)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_merge_feature(os.path.join(DATAPATH, 'taxibj.npz'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 train/val/test division\n",
    "\n",
    "The total number of timestamps is 21360, the number of timestamps in one day is 48 --> # days = 21360 / 48 = 445\n",
    "- train_data: the data of first `389` days, timestamps[:18672]\n",
    "  - train_data -- (18672, 2, 32, 32)\n",
    "  - train_slots -- (18672,)\n",
    "  - train_meta_feature -- (18672, 28 + #time_periods)\n",
    "- val_data: the data of the following `28` days, 28, timestamps[18672:21016]\n",
    "  - val_data -- (1344, 2, 32, 32)\n",
    "  - val_slots -- (1344,)\n",
    "  - val_meta_feature -- (1344, 28 + #time_periods)\n",
    "- test_date: the data of the last `28` days, timestamps[-1344:]\n",
    "  - test_data -- (1344, 2, 32, 32)\n",
    "  - test_slots -- (1344,)\n",
    "  - test_meta_feature -- (1344, 28 + #time_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_dataset(file_path, train_days=389, val_days=28, test_days=28, T=48, use_meta_feature=True):\n",
    "    \n",
    "    data_all = np.load(open(file_path, 'rb'))\n",
    "\n",
    "    train_data = data_all['data'][:train_days * T]\n",
    "    train_slots = data_all['timestamp'][:train_days * T]\n",
    "    val_data = data_all['data'][train_days * T : (train_days + val_days) * T]\n",
    "    val_slots = data_all['timestamp'][train_days * T : (train_days + val_days) * T]\n",
    "    test_data = data_all['data'][-test_days * T:]\n",
    "    test_slots = data_all['timestamp'][-test_days * T:]\n",
    "    if use_meta_feature:\n",
    "        train_meta_feature = data_all['meta_feature'][:train_days * T]\n",
    "        val_meta_feature =  data_all['meta_feature'][train_days * T : (train_days + val_days) * T]\n",
    "        test_meta_feature = data_all['meta_feature'][-test_days * T:]\n",
    "    \n",
    "    data_split = {\n",
    "            'train_data': train_data,\n",
    "            'train_slots': train_slots,\n",
    "            'val_data': val_data,\n",
    "            'val_slots': val_slots,\n",
    "            'test_data': test_data,\n",
    "            'test_slots': test_slots,\n",
    "            'train_meta_feature': train_meta_feature if use_meta_feature else None,\n",
    "            'val_meta_feature': val_meta_feature if use_meta_feature else None,\n",
    "            'test_meta_feature': test_meta_feature if use_meta_feature else None\n",
    "            }\n",
    "\n",
    "    data_all.close()\n",
    "    return data_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = split_dataset('f:/sosa_data/TaxiBJ/taxibj.npz')\n",
    "\n",
    "np.savez('f:/sosa_data/TaxiBJ/taxibj_split.npz',\n",
    "        train_data = data_split['train_data'],\n",
    "        train_slots = data_split['train_slots'],\n",
    "        val_data = data_split['val_data'],\n",
    "        val_slots = data_split['val_slots'],\n",
    "        test_data = data_split['test_data'],\n",
    "        test_slots = data_split['test_slots'],\n",
    "        train_meta_feature = data_split['train_meta_feature'],\n",
    "        val_meta_feature = data_split['val_meta_feature'],\n",
    "        test_meta_feature = data_split['test_meta_feature'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. visual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig_flow = plt.figure(num=1, figsize=(25, 18))\n",
    "\n",
    "ax1 = fig_flow.add_subplot(311)\n",
    "# ax1.plot(data_split['test_data'][-48:, 0, 0, 0], [i for i in range(48)])\n",
    "ax1.plot(data_split['test_data'][-48*14:, 0, 12, 12], 'r-', label='location (12, 12)') \n",
    "ax1.plot(data_split['test_data'][-48*14:, 0, 12, 13], 'g-', label='location (12, 13)') \n",
    "ax1.plot(data_split['test_data'][-48*14:, 0, 13, 12], 'b-', label='location (13, 12)') \n",
    "ax1.set_xticks(np.linspace(0, 48*14, 14))\n",
    "ax1.set_xticklabels(i for i in range(1,15))\n",
    "ax1.set_title('Inflow data of the last 14 days in test set')\n",
    "ax1.legend(loc=1, labelspacing=2)\n",
    "\n",
    "\n",
    "ax2 = fig_flow.add_subplot(312)\n",
    "ax2.plot(data_split['val_data'][-48*14:, 0, 12, 12], 'r-', label='location (12, 12)') \n",
    "ax2.plot(data_split['val_data'][-48*14:, 0, 12, 13], 'g-', label='location (12, 13)') \n",
    "ax2.plot(data_split['val_data'][-48*14:, 0, 13, 12], 'b-', label='location (13, 12)') \n",
    "ax2.set_xticks(np.linspace(0, 48*14, 14))\n",
    "ax2.set_xticklabels(i for i in range(1,15))\n",
    "ax2.set_title('Inflow data of the last 14 days in validation set')\n",
    "ax2.legend(loc=1, labelspacing=2)\n",
    "\n",
    "\n",
    "ax3 = fig_flow.add_subplot(313)\n",
    "ax3.plot(data_split['train_data'][-48*14:, 0, 12, 12], 'r-', label='location (12, 12)') \n",
    "ax3.plot(data_split['train_data'][-48*14:, 0, 12, 13], 'g-', label='location (12, 13)') \n",
    "ax3.plot(data_split['train_data'][-48*14:, 0, 13, 12], 'b-', label='location (13, 12)') \n",
    "ax3.set_xticks(np.linspace(0, 48*14, 14))\n",
    "ax3.set_xticklabels(i for i in range(1,15))\n",
    "ax3.set_title('Inflow data of the last 14 days in training set')\n",
    "ax3.legend(loc=1, labelspacing=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(4,2,3,3)\n",
    "b = np.vstack((a[0], a[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cannot import  from partially initialized module (most likely due to a circular import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'f:/sosa_data/TaxiBJ/processed/'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
